{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Join the Duet Server the Data Owner connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duet server provided by Open minded\n",
    "Checkpoint 0 : Now STOP and run the Data Owner notebook until Checkpoint 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Search for Available Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data scientist can check the list of pointable data in Data Owner's duet store\n",
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scientist wants to get the Crop dataset. (S)He needs a pointer to the data and\n",
    "# a pointer to the target for prediction.\n",
    "data_ptr = duet.store[0]\n",
    "target_ptr = duet.store[1]\n",
    "\n",
    "# data_ptr.requires_grad = True\n",
    "# target_ptr.requires_grad = True\n",
    "\n",
    "# data_ptr is a reference to the Crop dataset remotely available on data owner's server\n",
    "# target_ptr is a reference to the Crop dataset LABELS\n",
    "# remotely available on data owner's server\n",
    "print(data_ptr)\n",
    "print(target_ptr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Part 3: Perform Logistic Regression on Crop dataset\n",
    "Now the data scientist can perform machine learning on the data that is in the Data Owner's duet server, without the owner having to share his/her data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data scientist needs to know some basic information about the dataset.\n",
    "1. The length of the dataset\n",
    "2. The input dimension\n",
    "3. The output dimension\n",
    "\n",
    "These information have to explicitly shared by the Data Owner. Let's try to find them in the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duet.store.pandas[\"Description\"][0])\n",
    "\n",
    "print(duet.store.pandas[\"Description\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 4\n",
    "out_dim = 3\n",
    "n_samples = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.layer1 = self.torch_ref.nn.Linear(in_dim, 20)\n",
    "        self.layer2 = self.torch_ref.nn.Linear(20, 30)\n",
    "        self.out = self.torch_ref.nn.Linear(30, out_dim)\n",
    "        #self.flatten = self.torch_ref.nn.Flatten()\n",
    "    def forward(self, X111):\n",
    "        X111 = self.torch_ref.nn.functional.relu(self.layer1(X111))\n",
    "        X111 = self.torch_ref.nn.functional.relu(self.layer2(X111))\n",
    "        output = self.torch_ref.nn.functional.log_softmax(self.out(X111), dim=1)\n",
    "        #self.torch_ref.nn.Flatten(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model = local_model.send(duet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I create an alias for our partnerâ€™s torch called remote_torch so we can refer to the local torch as torch and any operation we want to do remotely as remote_torch. Remember, the return values from remote_torch are Pointers, not the real objects. They mostly act the same when using them with other Pointers but you can't mix them with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = remote_model.parameters()\n",
    "optim = remote_torch.optim.Adam(params=params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remote_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr.long())\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\", request_block=True, timeout_secs=5\n",
    "        )\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses\n",
    "print(\"Computational time :- %s seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteration = 300\n",
    "losses = train(iteration, remote_model, remote_torch, optim, data_ptr, target_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Crop Type, Loss vs iteration')\n",
    "plt.plot(range(iteration), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"iteration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_model(model):\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"To run test and inference locally\",\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "\n",
    "    return local_model\n",
    "\n",
    "\n",
    "local_model = get_local_model(remote_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_test = pd.read_csv(f\"Crop_test_data_Artharva1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df2 = StandardScaler().fit_transform(crop_test.iloc[:, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test = df.loc[:, crop_test.columns != \"label\"]\n",
    "yy_test = crop_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX1_test = torch.FloatTensor(np.array(XX_test))\n",
    "yy1_test = torch.LongTensor(np.array(yy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    #local_model.eval()\n",
    "    for i in range(len(XX1_test)):\n",
    "        sample = XX1_test[i]\n",
    "        #try replacing X_test[i] with X_test[i:i+1]\n",
    "        y_hat = local_model(sample.unsqueeze(0))\n",
    "        pred = y_hat.argmax().item()\n",
    "        #pred = y_hat.max().item()\n",
    "        #CATEGORIES[np.argmax(pred)]\n",
    "        print(f\"Prediction: {pred} Ground Truth: {yy1_test[i]}\")\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted crop is\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(yy1_test, preds)\n",
    "print(\"Overall test accuracy\", acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Crop Type Predictions and Ground Truth')\n",
    "\n",
    "plt.plot(preds, label='pred')\n",
    "plt.plot(yy1_test, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Base Model parameters:\")\n",
    "print(remote_model)\n",
    "print()\n",
    "\n",
    "#print(\"Remote model1 parameters:\")\n",
    "#print(remote_torch)\n",
    "print()\n",
    "\n",
    "#print(\"Remote model2 parameters:\")\n",
    "#print(param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yy1_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
